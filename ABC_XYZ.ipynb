{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnUIMKw/7yV1BMbAIShbUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/blob/main/ABC_XYZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxGeIMfTrAzz",
        "outputId": "49fd1986-2b66-4190-ca36-d37e3ed14aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clasificación ABC de Productos\n",
            "============================================================\n",
            "         ITEM  Total_Ventas_Anual  Precio  Valor_Total_Dolares  \\\n",
            "0     ITEM 12             4895280    7.82          38281089.60   \n",
            "1      ITEM 2             8292408    4.17          34579341.36   \n",
            "2      ITEM 1             4827108    6.84          33017418.72   \n",
            "3      ITEM 7             7351524    4.35          31979129.40   \n",
            "4    ITEM 311             5234976    5.66          29629964.16   \n",
            "..        ...                 ...     ...                  ...   \n",
            "655  ITEM 472             2763960    1.62           4477615.20   \n",
            "656  ITEM 625             2355924    1.87           4405577.88   \n",
            "657  ITEM 624             2399628    1.72           4127360.16   \n",
            "658  ITEM 655             2364588    1.56           3688757.28   \n",
            "659  ITEM 639             3795540    0.80           3036432.00   \n",
            "\n",
            "     Porcentaje_Acumulado Clase_ABC  \n",
            "0                0.407538         A  \n",
            "1                0.775668         A  \n",
            "2                1.127169         A  \n",
            "3                1.467617         A  \n",
            "4                1.783056         A  \n",
            "..                    ...       ...  \n",
            "655             99.837563         C  \n",
            "656             99.884464         C  \n",
            "657             99.928404         C  \n",
            "658             99.967674         C  \n",
            "659            100.000000         C  \n",
            "\n",
            "[660 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer las hojas del Excel\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# Asegurar que la columna ITEM esté como índice o string limpio\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Eliminar espacios innecesarios en nombres de columnas\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Sumar las ventas mensuales para obtener venta anual\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Convertir precios a número (eliminando '$' y comas)\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)\n",
        "\n",
        "# Unir datos: Total de ventas con precio\n",
        "merged_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "\n",
        "# Calcular valor total en dólares (ventas * precio)\n",
        "merged_df['Valor_Total_Dolares'] = merged_df['Total_Ventas_Anual'] * merged_df['Precio']\n",
        "\n",
        "# Ordenar por valor total descendente\n",
        "merged_df = merged_df.sort_values(by='Valor_Total_Dolares', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Calcular el total general\n",
        "total_valor = merged_df['Valor_Total_Dolares'].sum()\n",
        "\n",
        "# Calcular porcentaje acumulado\n",
        "merged_df['Porcentaje_Acumulado'] = merged_df['Valor_Total_Dolares'].cumsum() / total_valor * 100\n",
        "\n",
        "# Clasificación ABC\n",
        "def clasificar_abc(porcentaje_acumulado):\n",
        "    if porcentaje_acumulado <= 60:\n",
        "        return 'A'\n",
        "    elif porcentaje_acumulado <= 80:\n",
        "        return 'B'\n",
        "    else:\n",
        "        return 'C'\n",
        "\n",
        "merged_df['Clase_ABC'] = merged_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación ABC de Productos\")\n",
        "print(\"=\"*60)\n",
        "print(merged_df[['ITEM', 'Total_Ventas_Anual', 'Precio', 'Valor_Total_Dolares', 'Porcentaje_Acumulado', 'Clase_ABC']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FTLLJ5wv26uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer la hoja 'Historico'\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "\n",
        "# Asegurar que ITEM es string limpio\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Eliminar espacios en nombres de columnas\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "\n",
        "# Identificar columnas de meses (excluyendo 'ITEM')\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Convertir todos los valores numéricos a float\n",
        "for col in month_cols:\n",
        "    historico_df[col] = pd.to_numeric(historico_df[col], errors='coerce')\n",
        "\n",
        "# Función para limpieza de datos por ítem\n",
        "def limpiar_datos(item_data):\n",
        "    # Reemplazar valores <= 0 por la mediana del ítem\n",
        "    median_val = item_data.median()\n",
        "    item_data_clean = item_data.clip(lower=median_val)  # Esto reemplaza valores < median_val por median_val\n",
        "    return item_data_clean\n",
        "\n",
        "# Aplicar limpieza por ítem\n",
        "data_cleaned = historico_df.copy()\n",
        "for col in month_cols:\n",
        "    data_cleaned[col] = data_cleaned.groupby('ITEM')[col].transform(limpiar_datos)\n",
        "\n",
        "# Aplicar Winzorización: reemplazar valores fuera de 5% y 95%\n",
        "def winzorize_series(series):\n",
        "    p5 = series.quantile(0.05)\n",
        "    p95 = series.quantile(0.95)\n",
        "    return series.clip(lower=p5, upper=p95)\n",
        "\n",
        "# Aplicar Winzorización por ítem\n",
        "for col in month_cols:\n",
        "    data_cleaned[col] = data_cleaned.groupby('ITEM')[col].transform(winzorize_series)\n",
        "\n",
        "# Calcular coeficiente de variación (CV) para cada ítem\n",
        "cv_data = []\n",
        "for idx, row in data_cleaned.iterrows():\n",
        "    item = row['ITEM']\n",
        "    values = row[month_cols].dropna().values\n",
        "    if len(values) == 0:\n",
        "        cv = np.nan\n",
        "    else:\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values, ddof=1)  # desviación estándar muestral\n",
        "        if mean_val == 0:\n",
        "            cv = np.inf  # si media es cero, CV no definido\n",
        "        else:\n",
        "            cv = std_val / mean_val\n",
        "    cv_data.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "cv_df = pd.DataFrame(cv_data)\n",
        "\n",
        "# Ordenar por CV ascendente\n",
        "cv_df = cv_df.sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentiles\n",
        "cv_df['Percentil'] = cv_df['CV'].rank(pct=True) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ por Coeficiente de Variación\")\n",
        "print(\"=\"*70)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "3Qjhg2yuyycJ",
        "outputId": "327ddee7-9b95-4209-8d94-8a0692c36709"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "arg must be a list, tuple, 1-d array, or Series",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-241045634.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Convertir todos los valores numéricos a float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Función para limpieza de datos por ítem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arg must be a list, tuple, 1-d array, or Series\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer la hoja 'Historico'\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "\n",
        "# Asegurar que ITEM es string limpio\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Eliminar espacios en nombres de columnas\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "\n",
        "# Identificar columnas de meses (todas excepto 'ITEM')\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Convertir cada columna de meses a numérico, celda por celda\n",
        "for col in month_cols:\n",
        "    historico_df[col] = historico_df[col].astype(str).str.strip()  # Convertir a string y limpiar\n",
        "    historico_df[col] = pd.to_numeric(historico_df[col], errors='coerce')  # Convertir a numérico, NaN si falla\n",
        "\n",
        "# Función para limpiar datos por ítem: reemplazar ceros/negativos por mediana\n",
        "def limpiar_datos(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    median_val = np.median(values[~np.isnan(values)])  # Mediana sin NaN\n",
        "    group[month_cols] = group[month_cols].clip(lower=median_val, axis=0)  # Reemplazar valores bajos\n",
        "    return group\n",
        "\n",
        "# Aplicar limpieza por ITEM\n",
        "data_cleaned = historico_df.groupby('ITEM', group_keys=False).apply(limpiar_datos)\n",
        "\n",
        "# Winzorización: reemplazar extremos por percentiles 5% y 95% por ITEM\n",
        "def winzorize_group(group):\n",
        "    data = group[month_cols].values.flatten()\n",
        "    p5 = np.nanpercentile(data, 5)\n",
        "    p95 = np.nanpercentile(data, 95)\n",
        "    group[month_cols] = np.clip(group[month_cols], p5, p95)\n",
        "    return group\n",
        "\n",
        "data_cleaned = data_cleaned.groupby('ITEM', group_keys=False).apply(winzorize_group)\n",
        "\n",
        "# Calcular coeficiente de variación (CV) por ITEM\n",
        "cv_results = []\n",
        "for item, group in data_cleaned.groupby('ITEM'):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    values = values[~np.isnan(values)]  # Eliminar NaN\n",
        "    if len(values) == 0:\n",
        "        cv = np.nan\n",
        "    else:\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values, ddof=1)\n",
        "        cv = std_val / mean_val if mean_val != 0 else np.inf\n",
        "    cv_results.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "# Crear DataFrame de CV\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "\n",
        "# Ordenar por CV\n",
        "cv_df = cv_df.sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentil\n",
        "cv_df['Percentil'] = (cv_df['CV'].rank(method='min') - 1) / len(cv_df) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ por Coeficiente de Variación\")\n",
        "print(\"=\"*70)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "k0sysbnJy_YX",
        "outputId": "d4000eb8-f8bb-46c5-c313-0c3776be2ce4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2813969804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Convertir cada columna de meses a numérico, celda por celda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convertir a string y limpiar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convertir a numérico, NaN si falla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer la hoja 'Historico'\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "\n",
        "# Asegurar que ITEM es string limpio\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Limpiar nombres de columnas\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "\n",
        "# Columnas de meses\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Función para convertir un valor a número, limpiando espacios y caracteres extraños\n",
        "def clean_value(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    try:\n",
        "        # Convertir a string, limpiar espacios y caracteres extraños\n",
        "        x_str = str(x).strip().replace('$', '').replace(',', '').replace(' ', '')\n",
        "        return float(x_str)\n",
        "    except ValueError:\n",
        "        return np.nan  # Si no se puede convertir, NaN\n",
        "\n",
        "# Aplicar limpieza a cada columna de meses\n",
        "for col in month_cols:\n",
        "    historico_df[col] = historico_df[col].apply(clean_value)\n",
        "\n",
        "# Función para limpiar datos por grupo (reemplazar <=0 por mediana)\n",
        "def limpiar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[~np.isnan(values) & (values > 0)]  # Solo valores positivos y no NaN\n",
        "    if len(valid_values) == 0:\n",
        "        median_val = 1  # valor por defecto si todo es cero o negativo\n",
        "    else:\n",
        "        median_val = np.median(valid_values)\n",
        "\n",
        "    # Reemplazar valores <= 0 o NaN por la mediana\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: median_val if pd.isna(x) or x <= 0 else x)\n",
        "    return group\n",
        "\n",
        "# Aplicar limpieza por ITEM\n",
        "data_cleaned = historico_df.groupby('ITEM', group_keys=False).apply(limpiar_grupo)\n",
        "\n",
        "# Winzorización por ITEM: reemplazar valores extremos por percentiles 5% y 95%\n",
        "def winzorizar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[~np.isnan(values)]\n",
        "    if len(valid_values) < 2:\n",
        "        return group  # No hacer nada si no hay suficientes datos\n",
        "    p5 = np.percentile(valid_values, 5)\n",
        "    p95 = np.percentile(valid_values, 95)\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: p5 if x < p5 else (p95 if x > p95 else x))\n",
        "    return group\n",
        "\n",
        "data_cleaned = data_cleaned.groupby('ITEM', group_keys=False).apply(winzorizar_grupo)\n",
        "\n",
        "# Calcular coeficiente de variación (CV) por ITEM\n",
        "cv_results = []\n",
        "for item, group in data_cleaned.groupby('ITEM'):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    values = values[~np.isnan(values)]  # Eliminar NaN\n",
        "    if len(values) == 0 or np.mean(values) == 0:\n",
        "        cv = np.nan\n",
        "    else:\n",
        "        cv = np.std(values, ddof=1) / np.mean(values)\n",
        "    cv_results.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "# Crear DataFrame\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df = cv_df.dropna().sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentil\n",
        "cv_df['Percentil'] = (cv_df['CV'].rank(method='min') - 1) / len(cv_df) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ por Coeficiente de Variación\")\n",
        "print(\"=\"*70)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "L5EJ8hygzNk_",
        "outputId": "7241730b-0805-4796-9a64-d80667254276"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1267883098.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Aplicar limpieza a cada columna de meses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Función para limpiar datos por grupo (reemplazar <=0 por mediana)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1267883098.py\u001b[0m in \u001b[0;36mclean_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Función para convertir un valor a número, limpiando espacios y caracteres extraños\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer la hoja 'Historico'\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico', dtype=object)  # Leer todo como objeto\n",
        "\n",
        "# Limpiar nombres de columnas y ITEM\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Columnas de meses\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Función para convertir un valor a número limpio\n",
        "def clean_value(x):\n",
        "    if x is None or pd.isna(x):\n",
        "        return np.nan\n",
        "    try:\n",
        "        # Convertir a string, limpiar\n",
        "        x_str = str(x).strip().replace('$', '').replace(',', '').replace(' ', '')\n",
        "        if x_str == '' or x_str.lower() in ['na', 'nan', '-']:\n",
        "            return np.nan\n",
        "        return float(x_str)\n",
        "    except (ValueError, TypeError):\n",
        "        return np.nan\n",
        "\n",
        "# Reconstruir el DataFrame con valores limpios\n",
        "for col in month_cols:\n",
        "    historico_df[col] = historico_df[col].apply(lambda x: clean_value(x))\n",
        "\n",
        "# Asegurarnos de que todo sea numérico\n",
        "for col in month_cols:\n",
        "    historico_df[col] = pd.to_numeric(historico_df[col], errors='coerce')\n",
        "\n",
        "# Función para limpiar cada grupo (ITEM): reemplazar <=0 o NaN por mediana positiva\n",
        "def limpiar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[(~np.isnan(values)) & (values > 0)]\n",
        "    if len(valid_values) == 0:\n",
        "        median_val = 1.0\n",
        "    else:\n",
        "        median_val = np.median(valid_values)\n",
        "    # Reemplazar valores inválidos\n",
        "    group[month_cols] = group[month_cols].applymap(\n",
        "        lambda x: median_val if pd.isna(x) or x <= 0 else x\n",
        "    )\n",
        "    return group\n",
        "\n",
        "# Aplicar limpieza por ITEM\n",
        "data_cleaned = historico_df.groupby('ITEM', group_keys=False).apply(limpiar_grupo)\n",
        "\n",
        "# Winzorización por percentiles 5% y 95% por ITEM\n",
        "def winzorizar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[~np.isnan(values)]\n",
        "    if len(valid_values) < 2:\n",
        "        return group\n",
        "    p5 = np.percentile(valid_values, 5)\n",
        "    p95 = np.percentile(valid_values, 95)\n",
        "    group[month_cols] = group[month_cols].applymap(\n",
        "        lambda x: p5 if x < p5 else (p95 if x > p95 else x)\n",
        "    )\n",
        "    return group\n",
        "\n",
        "data_cleaned = data_cleaned.groupby('ITEM', group_keys=False).apply(winzorizar_grupo)\n",
        "\n",
        "# Calcular CV por ITEM\n",
        "cv_results = []\n",
        "for item, group in data_cleaned.groupby('ITEM'):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    values = values[~np.isnan(values)]\n",
        "    if len(values) == 0:\n",
        "        continue\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values, ddof=1)\n",
        "    cv = std_val / mean_val if mean_val != 0 else np.inf\n",
        "    cv_results.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "# Crear DataFrame final\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df = cv_df.replace([np.inf, -np.inf], np.nan).dropna().sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentil\n",
        "cv_df['Percentil'] = (cv_df['CV'].rank(method='min') - 1) / len(cv_df) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ - Demanda por estabilidad\")\n",
        "print(\"=\" * 60)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tQTMTugpznlH",
        "outputId": "19be6758-6e0f-41d6-f93b-d0411d4c036b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2892424212.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2892424212.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2892424212.py\u001b[0m in \u001b[0;36mclean_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Función para convertir un valor a número limpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que ya tienes el DataFrame `historico_df` cargado desde tu archivo Excel.\n",
        "# Si no, asegúrate de cargarlo correctamente antes de ejecutar este código.\n",
        "\n",
        "# Limpiar nombres de columnas y ITEM\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Columnas de meses\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Función para convertir un valor a número limpio\n",
        "def clean_value(x):\n",
        "    if x is None or pd.isna(x):\n",
        "        return np.nan\n",
        "    try:\n",
        "        x_str = str(x).strip().replace('$', '').replace(',', '').replace(' ', '')\n",
        "        if x_str == '' or x_str.lower() in ['na', 'nan', '-']:\n",
        "            return np.nan\n",
        "        return float(x_str)\n",
        "    except (ValueError, TypeError):\n",
        "        return np.nan\n",
        "\n",
        "# Reconstruir el DataFrame con valores limpios\n",
        "for col in month_cols:\n",
        "    historico_df[col] = historico_df[col].apply(lambda x: clean_value(x))\n",
        "\n",
        "# Asegurarnos de que todo sea numérico\n",
        "for col in month_cols:\n",
        "    historico_df[col] = pd.to_numeric(historico_df[col], errors='coerce')\n",
        "\n",
        "# Función para limpiar cada grupo (ITEM): reemplazar <=0 o NaN por mediana positiva\n",
        "def limpiar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[(~np.isnan(values)) & (values > 0)]\n",
        "    if len(valid_values) == 0:\n",
        "        median_val = 1.0\n",
        "    else:\n",
        "        median_val = np.median(valid_values)\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: median_val if pd.isna(x) or x <= 0 else x)\n",
        "    return group\n",
        "\n",
        "# Aplicar limpieza por ITEM\n",
        "data_cleaned = historico_df.groupby('ITEM', group_keys=False).apply(limpiar_grupo)\n",
        "\n",
        "# Winzorización por percentiles 5% y 95% por ITEM\n",
        "def winzorizar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[~np.isnan(values)]\n",
        "    if len(valid_values) < 2:\n",
        "        return group\n",
        "    p5 = np.percentile(valid_values, 5)\n",
        "    p95 = np.percentile(valid_values, 95)\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: p5 if x < p5 else (p95 if x > p95 else x))\n",
        "    return group\n",
        "\n",
        "data_cleaned = data_cleaned.groupby('ITEM', group_keys=False).apply(winzorizar_grupo)\n",
        "\n",
        "# Calcular CV por ITEM\n",
        "cv_results = []\n",
        "for item, group in data_cleaned.groupby('ITEM'):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    values = values[~np.isnan(values)]\n",
        "    if len(values) == 0:\n",
        "        continue\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values, ddof=1)\n",
        "    cv = std_val / mean_val if mean_val != 0 else np.inf\n",
        "    cv_results.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "# Crear DataFrame final\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df = cv_df.replace([np.inf, -np.inf], np.nan).dropna().sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentil\n",
        "cv_df['Percentil'] = (cv_df['CV'].rank(method='min') - 1) / len(cv_df) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ - Demanda por estabilidad\")\n",
        "print(\"=\" * 60)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7sxKLTXZ0VWv",
        "outputId": "114969d3-a051-4105-feb3-b7bd74b05b53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1272359838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1272359838.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1272359838.py\u001b[0m in \u001b[0;36mclean_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Función para convertir un valor a número limpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el archivo Excel\n",
        "historico_df = pd.read_excel('https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx', sheet_name='Historico', dtype=object)\n",
        "\n",
        "# Limpiar nombres de columnas y ITEM\n",
        "historico_df.columns = historico_df.columns.str.strip()\n",
        "historico_df['ITEM'] = historico_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Columnas de meses\n",
        "month_cols = [col for col in historico_df.columns if col != 'ITEM']\n",
        "\n",
        "# Función para convertir un valor a número limpio\n",
        "def clean_value(x):\n",
        "    if x is None or pd.isna(x):\n",
        "        return np.nan\n",
        "    try:\n",
        "        x_str = str(x).strip().replace('$', '').replace(',', '').replace(' ', '')\n",
        "        if x_str == '' or x_str.lower() in ['na', 'nan', '-']:\n",
        "            return np.nan\n",
        "        return float(x_str)\n",
        "    except (ValueError, TypeError):\n",
        "        return np.nan\n",
        "\n",
        "# Reconstruir el DataFrame con valores limpios\n",
        "for col in month_cols:\n",
        "    historico_df[col] = historico_df[col].apply(lambda x: clean_value(x))\n",
        "\n",
        "# Asegurarnos de que todo sea numérico\n",
        "for col in month_cols:\n",
        "    historico_df[col] = pd.to_numeric(historico_df[col], errors='coerce')\n",
        "\n",
        "# Función para limpiar cada grupo (ITEM): reemplazar <=0 o NaN por mediana positiva\n",
        "def limpiar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[(~np.isnan(values)) & (values > 0)]\n",
        "    if len(valid_values) == 0:\n",
        "        median_val = 1.0\n",
        "    else:\n",
        "        median_val = np.median(valid_values)\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: median_val if pd.isna(x) or x <= 0 else x)\n",
        "    return group\n",
        "\n",
        "# Aplicar limpieza por ITEM\n",
        "data_cleaned = historico_df.groupby('ITEM', group_keys=False).apply(limpiar_grupo)\n",
        "\n",
        "# Winzorización por percentiles 5% y 95% por ITEM\n",
        "def winzorizar_grupo(group):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    valid_values = values[~np.isnan(values)]\n",
        "    if len(valid_values) < 2:\n",
        "        return group\n",
        "    p5 = np.percentile(valid_values, 5)\n",
        "    p95 = np.percentile(valid_values, 95)\n",
        "    group[month_cols] = group[month_cols].applymap(lambda x: p5 if x < p5 else (p95 if x > p95 else x))\n",
        "    return group\n",
        "\n",
        "data_cleaned = data_cleaned.groupby('ITEM', group_keys=False).apply(winzorizar_grupo)\n",
        "\n",
        "# Calcular CV por ITEM\n",
        "cv_results = []\n",
        "for item, group in data_cleaned.groupby('ITEM'):\n",
        "    values = group[month_cols].values.flatten()\n",
        "    values = values[~np.isnan(values)]\n",
        "    if len(values) == 0:\n",
        "        continue\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values, ddof=1)\n",
        "    cv = std_val / mean_val if mean_val != 0 else np.inf\n",
        "    cv_results.append({'ITEM': item, 'CV': cv})\n",
        "\n",
        "# Crear DataFrame final\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df = cv_df.replace([np.inf, -np.inf], np.nan).dropna().sort_values(by='CV', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Calcular percentil\n",
        "cv_df['Percentil'] = (cv_df['CV'].rank(method='min') - 1) / len(cv_df) * 100\n",
        "\n",
        "# Clasificación XYZ\n",
        "def clasificar_xyz(percentil):\n",
        "    if percentil <= 33:\n",
        "        return 'X'\n",
        "    elif percentil <= 67:\n",
        "        return 'Y'\n",
        "    else:\n",
        "        return 'Z'\n",
        "\n",
        "cv_df['Clase_XYZ'] = cv_df['Percentil'].apply(clasificar_xyz)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Clasificación XYZ - Demanda por estabilidad\")\n",
        "print(\"=\" * 60)\n",
        "print(cv_df[['ITEM', 'CV', 'Percentil', 'Clase_XYZ']].round(4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "o-OdWKDl04hg",
        "outputId": "ffc0724f-551d-42d3-d085-ab6fb85f0ed7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-685727930.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-685727930.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reconstruir el DataFrame con valores limpios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorico_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Asegurarnos de que todo sea numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-685727930.py\u001b[0m in \u001b[0;36mclean_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Función para convertir un valor a número limpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Descargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "df = pd.read_excel(url, sheet_name=\"Historico\", index_col=\"ITEM\")\n",
        "\n",
        "# Seleccionar últimos 18 meses (feb-2024 a jul-2025)\n",
        "cols = df.columns[df.columns.get_loc(\"feb-24\"):df.columns.get_loc(\"jul-25\")+1]\n",
        "data = df[cols].copy()\n",
        "\n",
        "# Función para limpiar y winsorizar por fila\n",
        "def clean_row(row):\n",
        "    # Copiar fila\n",
        "    clean = row.copy()\n",
        "\n",
        "    # Reemplazar valores <=0 con la mediana\n",
        "    median = clean[clean > 0].median()\n",
        "    median = median if not np.isnan(median) else 0\n",
        "    clean[clean <= 0] = median\n",
        "\n",
        "    # Winsorización (solo si hay variabilidad)\n",
        "    if clean.nunique() > 1:\n",
        "        clean[:] = winsorize(clean, limits=[0.05, 0.05], nan_policy='omit')\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "data_clean = data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación (CV)\n",
        "mean = data_clean.mean(axis=1)\n",
        "std = data_clean.std(axis=1)\n",
        "cv = (std / mean).replace(np.inf, 1000).fillna(1000)  # Manejar casos con media=0\n",
        "\n",
        "# Clasificación XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "clasificacion = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# Resultado final\n",
        "resultado = pd.DataFrame({\n",
        "    'Media': mean.round(2),\n",
        "    'Desviación': std.round(2),\n",
        "    'CV': cv.round(2),\n",
        "    'Clasificación': clasificacion\n",
        "})\n",
        "\n",
        "print(\"Límites de clasificación:\")\n",
        "print(f\"- X: CV ≤ {p33:.2f} (Percentil 33)\")\n",
        "print(f\"- Y: {p33:.2f} < CV ≤ {p67:.2f} (Percentil 67)\")\n",
        "print(f\"- Z: CV > {p67:.2f}\\n\")\n",
        "print(\"Primeras 10 clasificaciones:\")\n",
        "print(resultado.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "bbClVSwM1tud",
        "outputId": "2e6b6f2f-2d37-4a61-e3b1-56919056f878"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'feb-24'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32mtimestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp._as_creso\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnp_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.convert_reso\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOverflowError\u001b[0m: result would overflow",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine._unbox_scalar\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mtimestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp._as_creso\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Cannot cast 0001-02-24 00:00:00 to unit='ns' without overflow.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Timestamp('1-02-24 00:00:00')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Timestamp('1-02-24 00:00:00')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2193988206.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Seleccionar últimos 18 meses (feb-2024 a jul-2025)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feb-24\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jul-25\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatetimeTimedeltaMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_slice_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'feb-24'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Descargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "df = pd.read_excel(url, sheet_name=\"Historico\", index_col=\"ITEM\")\n",
        "\n",
        "# Seleccionar últimos 18 meses por posición (feb-2024 a jul-2025)\n",
        "data = df.iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar y winsorizar por fila\n",
        "def clean_row(row):\n",
        "    # Copiar fila\n",
        "    clean = row.copy().astype(float)\n",
        "\n",
        "    # Reemplazar valores <=0 con la mediana\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    # Winsorización solo si hay suficientes valores distintos\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except ValueError:\n",
        "            pass  # Si falla, mantener valores originales\n",
        "\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "data_clean = data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación (CV)\n",
        "mean = data_clean.mean(axis=1)\n",
        "std = data_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "\n",
        "# Manejar casos especiales\n",
        "cv = cv.replace([np.inf, -np.inf], 1000)  # Para medias = 0\n",
        "cv = cv.fillna(1000)  # Para filas sin datos\n",
        "\n",
        "# Clasificación XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "clasificacion = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# Resultado final\n",
        "resultado = pd.DataFrame({\n",
        "    'Media': mean.round(2),\n",
        "    'Desviación': std.round(2),\n",
        "    'CV': cv.round(4),\n",
        "    'Clasificación': clasificacion\n",
        "})\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"=\"*60)\n",
        "print(\"Límites de clasificación:\")\n",
        "print(f\"- X: CV ≤ {p33:.4f} (Percentil 33)\")\n",
        "print(f\"- Y: {p33:.4f} < CV ≤ {p67:.4f} (Percentil 67)\")\n",
        "print(f\"- Z: CV > {p67:.4f}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total ítems clasificados: {len(resultado)}\")\n",
        "print(resultado['Clasificación'].value_counts())\n",
        "print(\"=\"*60)\n",
        "print(\"Ejemplo de ítems clasificados:\")\n",
        "print(resultado.sample(10, random_state=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuPmmgUx2NrB",
        "outputId": "0f2f6724-544d-484f-c9e1-dc68095c7e6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Límites de clasificación:\n",
            "- X: CV ≤ 0.1510 (Percentil 33)\n",
            "- Y: 0.1510 < CV ≤ 0.1583 (Percentil 67)\n",
            "- Z: CV > 0.1583\n",
            "============================================================\n",
            "Total ítems clasificados: 660\n",
            "Clasificación\n",
            "Y    224\n",
            "X    218\n",
            "Z    218\n",
            "Name: count, dtype: int64\n",
            "============================================================\n",
            "Ejemplo de ítems clasificados:\n",
            "             Media  Desviación      CV Clasificación\n",
            "ITEM                                                \n",
            "ITEM 548  29748.39     4272.86  0.1436             X\n",
            "ITEM 354  17354.72     2620.09  0.1510             X\n",
            "ITEM 500  23371.39     3534.81  0.1512             Y\n",
            "ITEM 174  19585.56     3101.69  0.1584             Z\n",
            "ITEM 242  27983.83     4185.15  0.1496             X\n",
            "ITEM 342  30780.00     4638.80  0.1507             X\n",
            "ITEM 648  21299.50     3503.52  0.1645             Z\n",
            "ITEM 219  31940.06     4907.00  0.1536             Y\n",
            "ITEM 121  44915.33     6956.74  0.1549             Y\n",
            "ITEM 135  29912.11     4983.50  0.1666             Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico', index_col='ITEM')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses\n",
        "xyz_data = historico_df.iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "xyz_df = pd.DataFrame({\n",
        "    'Media_Demanda': mean,\n",
        "    'Desviacion_Demanda': std,\n",
        "    'CV': cv\n",
        "})\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Preparar DataFrames para merge\n",
        "abc_df = abc_df.set_index('ITEM')\n",
        "xyz_df = xyz_df[['CV', 'Clase_XYZ']]  # Solo necesitamos estas columnas\n",
        "\n",
        "# Hacer merge\n",
        "final_df = abc_df.merge(xyz_df, left_index=True, right_index=True, how='inner')\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'] + final_df['Clase_XYZ']\n",
        "\n",
        "# 5. Resultados\n",
        "print(\"=\"*80)\n",
        "print(f\"Total productos clasificados: {len(final_df)}\")\n",
        "print(\"Distribución ABC:\")\n",
        "print(final_df['Clase_ABC'].value_counts())\n",
        "print(\"\\nDistribución XYZ:\")\n",
        "print(final_df['Clase_XYZ'].value_counts())\n",
        "print(\"\\nDistribución ABC-XYZ:\")\n",
        "print(final_df['Clasificacion_ABC_XYZ'].value_counts())\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mostrar ejemplo de resultados\n",
        "print(\"Ejemplo de clasificación combinada:\")\n",
        "print(final_df.sample(10, random_state=1)[[\n",
        "    'Total_Ventas_Anual', 'Valor_Total_Dolares', 'Porcentaje_Acumulado',\n",
        "    'CV', 'Clase_ABC', 'Clase_XYZ', 'Clasificacion_ABC_XYZ'\n",
        "]].round(2))\n",
        "\n",
        "# 6. Exportar resultados (opcional)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\")\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fWudxO6N29BY",
        "outputId": "0619088d-3279-4940-fd6a-125258c30f0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Object with dtype category cannot perform the numpy op add",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3391958119.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Hacer merge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clasificacion_ABC_XYZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clase_ABC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clase_XYZ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# 5. Resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mmoose\u001b[0m     \u001b[0;36m3.0\u001b[0m     \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \"\"\"\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__radd__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_asobject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# because numexpr will fail on it, see GH#31457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# TODO we should handle EAs consistently and move this check before the if/else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0;31m# for all other cases, raise for now (similarly as what happens in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;31m# Series.__array_prepare__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   1695\u001b[0m             \u001b[0;34mf\"Object with dtype {self.dtype} cannot perform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m             \u001b[0;34mf\"the numpy op {ufunc.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object with dtype category cannot perform the numpy op add"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico', index_col='ITEM')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses\n",
        "xyz_data = historico_df.iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "xyz_df = pd.DataFrame({\n",
        "    'Media_Demanda': mean,\n",
        "    'Desviacion_Demanda': std,\n",
        "    'CV': cv\n",
        "})\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Preparar DataFrames para merge\n",
        "abc_df = abc_df.set_index('ITEM')\n",
        "xyz_df = xyz_df[['CV', 'Clase_XYZ']]  # Solo necesitamos estas columnas\n",
        "\n",
        "# Hacer merge\n",
        "final_df = abc_df.merge(xyz_df, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "# CORRECCIÓN: Convertir categorías a strings antes de concatenar\n",
        "final_df['Clase_ABC'] = final_df['Clase_ABC'].astype(str)\n",
        "final_df['Clase_XYZ'] = final_df['Clase_XYZ'].astype(str)\n",
        "\n",
        "# Crear clasificación combinada\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'] + final_df['Clase_XYZ']\n",
        "\n",
        "# 5. Resultados\n",
        "print(\"=\"*80)\n",
        "print(f\"Total productos clasificados: {len(final_df)}\")\n",
        "print(\"Distribución ABC:\")\n",
        "print(final_df['Clase_ABC'].value_counts())\n",
        "print(\"\\nDistribución XYZ:\")\n",
        "print(final_df['Clase_XYZ'].value_counts())\n",
        "print(\"\\nDistribución ABC-XYZ:\")\n",
        "print(final_df['Clasificacion_ABC_XYZ'].value_counts())\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mostrar ejemplo de resultados\n",
        "print(\"Ejemplo de clasificación combinada:\")\n",
        "print(final_df.sample(10, random_state=1)[[\n",
        "    'Total_Ventas_Anual', 'Valor_Total_Dolares', 'Porcentaje_Acumulado',\n",
        "    'CV', 'Clase_ABC', 'Clase_XYZ', 'Clasificacion_ABC_XYZ'\n",
        "]].round(2))\n",
        "\n",
        "# 6. Exportar resultados (opcional)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\")\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK2lH6xd3FUi",
        "outputId": "12fe03c8-9aab-4842-8a19-5f11588681ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Total productos clasificados: 660\n",
            "Distribución ABC:\n",
            "Clase_ABC\n",
            "A    299\n",
            "C    214\n",
            "B    147\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución XYZ:\n",
            "Clase_XYZ\n",
            "Y    224\n",
            "X    218\n",
            "Z    218\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución ABC-XYZ:\n",
            "Clasificacion_ABC_XYZ\n",
            "AY    116\n",
            "AZ    106\n",
            "CX     87\n",
            "AX     77\n",
            "CY     68\n",
            "CZ     59\n",
            "BX     54\n",
            "BZ     53\n",
            "BY     40\n",
            "Name: count, dtype: int64\n",
            "================================================================================\n",
            "Ejemplo de clasificación combinada:\n",
            "          Total_Ventas_Anual  Valor_Total_Dolares  Porcentaje_Acumulado    CV  \\\n",
            "ITEM                                                                            \n",
            "ITEM 114             2912004           9260172.72                 91.26  0.16   \n",
            "ITEM 244             3959916          13028123.64                 67.90  0.16   \n",
            "ITEM 570             3976404          10298886.36                 86.26  0.15   \n",
            "ITEM 341             4993920          17129145.60                 39.07  0.16   \n",
            "ITEM 427             4098360          15573768.00                 50.93  0.15   \n",
            "ITEM 78              4286556          13245458.04                 66.22  0.16   \n",
            "ITEM 356             2611332           5744930.40                 99.41  0.14   \n",
            "ITEM 96              5480208          16166613.60                 47.04  0.15   \n",
            "ITEM 243             4270944          19133829.12                 28.87  0.16   \n",
            "ITEM 3               6397464          18552645.60                 31.67  0.16   \n",
            "\n",
            "         Clase_ABC Clase_XYZ Clasificacion_ABC_XYZ  \n",
            "ITEM                                                \n",
            "ITEM 114         C         Z                    CZ  \n",
            "ITEM 244         B         Y                    BY  \n",
            "ITEM 570         C         Y                    CY  \n",
            "ITEM 341         A         Y                    AY  \n",
            "ITEM 427         A         Y                    AY  \n",
            "ITEM 78          B         Z                    BZ  \n",
            "ITEM 356         C         X                    CX  \n",
            "ITEM 96          A         X                    AX  \n",
            "ITEM 243         A         Z                    AZ  \n",
            "ITEM 3           A         Z                    AZ  \n",
            "\n",
            "Resultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico', index_col='ITEM')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses\n",
        "xyz_data = historico_df.iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "xyz_df = pd.DataFrame({\n",
        "    'Media_Demanda': mean,\n",
        "    'Desviacion_Demanda': std,\n",
        "    'CV': cv\n",
        "})\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Preparar DataFrames para merge\n",
        "abc_df = abc_df.set_index('ITEM')\n",
        "xyz_df = xyz_df[['CV', 'Clase_XYZ']]  # Solo necesitamos estas columnas\n",
        "\n",
        "# Hacer merge\n",
        "final_df = abc_df.merge(xyz_df, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "# CORRECCIÓN: Convertir categorías a strings antes de concatenar\n",
        "final_df['Clase_ABC'] = final_df['Clase_ABC'].astype(str)\n",
        "final_df['Clase_XYZ'] = final_df['Clase_XYZ'].astype(str)\n",
        "\n",
        "# Crear clasificación combinada\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'] + final_df['Clase_XYZ']\n",
        "\n",
        "# 5. Resultados\n",
        "print(\"=\"*80)\n",
        "print(f\"Total productos clasificados: {len(final_df)}\")\n",
        "print(\"Distribución ABC:\")\n",
        "print(final_df['Clase_ABC'].value_counts())\n",
        "print(\"\\nDistribución XYZ:\")\n",
        "print(final_df['Clase_XYZ'].value_counts())\n",
        "print(\"\\nDistribución ABC-XYZ:\")\n",
        "print(final_df['Clasificacion_ABC_XYZ'].value_counts())\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mostrar ejemplo de resultados\n",
        "print(\"Ejemplo de clasificación combinada:\")\n",
        "print(final_df.sample(10, random_state=1)[[\n",
        "    'Total_Ventas_Anual', 'Valor_Total_Dolares', 'Porcentaje_Acumulado',\n",
        "    'CV', 'Clase_ABC', 'Clase_XYZ', 'Clasificacion_ABC_XYZ'\n",
        "]].round(2))\n",
        "\n",
        "# 6. Exportar resultados (opcional)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\")\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSN7IVuG6TId",
        "outputId": "ba23da63-3505-4a59-914a-15552b1055bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Total productos clasificados: 660\n",
            "Distribución ABC:\n",
            "Clase_ABC\n",
            "A    299\n",
            "C    214\n",
            "B    147\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución XYZ:\n",
            "Clase_XYZ\n",
            "Y    224\n",
            "X    218\n",
            "Z    218\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución ABC-XYZ:\n",
            "Clasificacion_ABC_XYZ\n",
            "AY    116\n",
            "AZ    106\n",
            "CX     87\n",
            "AX     77\n",
            "CY     68\n",
            "CZ     59\n",
            "BX     54\n",
            "BZ     53\n",
            "BY     40\n",
            "Name: count, dtype: int64\n",
            "================================================================================\n",
            "Ejemplo de clasificación combinada:\n",
            "          Total_Ventas_Anual  Valor_Total_Dolares  Porcentaje_Acumulado    CV  \\\n",
            "ITEM                                                                            \n",
            "ITEM 114             2912004           9260172.72                 91.26  0.16   \n",
            "ITEM 244             3959916          13028123.64                 67.90  0.16   \n",
            "ITEM 570             3976404          10298886.36                 86.26  0.15   \n",
            "ITEM 341             4993920          17129145.60                 39.07  0.16   \n",
            "ITEM 427             4098360          15573768.00                 50.93  0.15   \n",
            "ITEM 78              4286556          13245458.04                 66.22  0.16   \n",
            "ITEM 356             2611332           5744930.40                 99.41  0.14   \n",
            "ITEM 96              5480208          16166613.60                 47.04  0.15   \n",
            "ITEM 243             4270944          19133829.12                 28.87  0.16   \n",
            "ITEM 3               6397464          18552645.60                 31.67  0.16   \n",
            "\n",
            "         Clase_ABC Clase_XYZ Clasificacion_ABC_XYZ  \n",
            "ITEM                                                \n",
            "ITEM 114         C         Z                    CZ  \n",
            "ITEM 244         B         Y                    BY  \n",
            "ITEM 570         C         Y                    CY  \n",
            "ITEM 341         A         Y                    AY  \n",
            "ITEM 427         A         Y                    AY  \n",
            "ITEM 78          B         Z                    BZ  \n",
            "ITEM 356         C         X                    CX  \n",
            "ITEM 96          A         X                    AX  \n",
            "ITEM 243         A         Z                    AZ  \n",
            "ITEM 3           A         Z                    AZ  \n",
            "\n",
            "Resultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico', index_col='ITEM')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses\n",
        "xyz_data = historico_df.iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "xyz_df = pd.DataFrame({\n",
        "    'ITEM': xyz_clean.index,\n",
        "    'CV': cv\n",
        "})\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Seleccionar solo las columnas necesarias de ABC\n",
        "abc_minimal = abc_df[['ITEM', 'Clase_ABC']]\n",
        "\n",
        "# Hacer merge usando la columna ITEM\n",
        "final_df = abc_minimal.merge(xyz_df[['ITEM', 'Clase_XYZ']], on='ITEM', how='inner')\n",
        "\n",
        "# Crear clasificación combinada\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'] + final_df['Clase_XYZ']\n",
        "\n",
        "# 5. Exportar resultado final (solo clasificaciones)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\", index=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DataFrame final exportado con las columnas:\")\n",
        "print(final_df.columns.tolist())\n",
        "print(f\"\\nTotal de ítems clasificados: {len(final_df)}\")\n",
        "print(\"\\nEjemplo de clasificaciones:\")\n",
        "print(final_df.sample(5, random_state=1))\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rMeEVOXl7Kuj",
        "outputId": "8b2ade0b-9c0f-4fd3-8727-b3a15c435121"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'ITEM' is both an index level and a column label, which is ambiguous.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3815481024.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Hacer merge usando la columna ITEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc_minimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ITEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Clase_XYZ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ITEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Crear clasificación combinada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_label_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                 \u001b[0;34mf\"{label_article} {label_type} label, which is ambiguous.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m             )\n\u001b[0;32m-> 1868\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'ITEM' is both an index level and a column label, which is ambiguous."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses de datos históricos\n",
        "xyz_data = historico_df.set_index('ITEM').iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "xyz_df = pd.DataFrame({\n",
        "    'ITEM': xyz_clean.index,\n",
        "    'CV': cv\n",
        "})\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Seleccionar solo las columnas necesarias de ABC\n",
        "abc_minimal = abc_df[['ITEM', 'Clase_ABC']]\n",
        "\n",
        "# Hacer merge usando la columna ITEM\n",
        "final_df = abc_minimal.merge(xyz_df[['ITEM', 'Clase_XYZ']], on='ITEM', how='inner')\n",
        "\n",
        "# Crear clasificación combinada\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'] + final_df['Clase_XYZ']\n",
        "\n",
        "# 5. Exportar resultado final (solo clasificaciones)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\", index=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DataFrame final exportado con las columnas:\")\n",
        "print(final_df.columns.tolist())\n",
        "print(f\"\\nTotal de ítems clasificados: {len(final_df)}\")\n",
        "print(\"\\nEjemplo de clasificaciones:\")\n",
        "print(final_df.sample(5, random_state=1))\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8gGD6KHz7wyM",
        "outputId": "a07f2698-9d66-4829-f730-1c44eb43d6b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'ITEM' is both an index level and a column label, which is ambiguous.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-672620974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Hacer merge usando la columna ITEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc_minimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ITEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Clase_XYZ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ITEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Crear clasificación combinada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_label_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                 \u001b[0;34mf\"{label_article} {label_type} label, which is ambiguous.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m             )\n\u001b[0;32m-> 1868\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'ITEM' is both an index level and a column label, which is ambiguous."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "\n",
        "# 2. Clasificación ABC\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "\n",
        "# 3. Clasificación XYZ\n",
        "# Seleccionar últimos 18 meses de datos históricos\n",
        "xyz_data = historico_df.set_index('ITEM').iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos\n",
        "def clean_row(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ - CORRECCIÓN AQUÍ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "\n",
        "# Resetear el índice para convertir el índice 'ITEM' en una columna normal\n",
        "xyz_df = pd.DataFrame({\n",
        "    'ITEM': xyz_clean.index.tolist(),  # Convertir explícitamente a lista\n",
        "    'CV': cv.values  # Usar .values para obtener los valores sin el índice\n",
        "}).reset_index(drop=True)  # Resetear índice para evitar conflictos\n",
        "\n",
        "# Aplicar clasificación XYZ\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv.values, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# Convertir la columna ITEM a string para asegurar consistencia\n",
        "xyz_df['ITEM'] = xyz_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# 4. Combinar ABC y XYZ\n",
        "# Seleccionar solo las columnas necesarias de ABC\n",
        "abc_minimal = abc_df[['ITEM', 'Clase_ABC']].copy()\n",
        "\n",
        "# Asegurar que ambas columnas ITEM sean del mismo tipo\n",
        "abc_minimal['ITEM'] = abc_minimal['ITEM'].astype(str).str.strip()\n",
        "\n",
        "# Hacer merge usando la columna ITEM\n",
        "final_df = abc_minimal.merge(xyz_df[['ITEM', 'Clase_XYZ']], on='ITEM', how='inner')\n",
        "\n",
        "# Crear clasificación combinada\n",
        "final_df['Clasificacion_ABC_XYZ'] = final_df['Clase_ABC'].astype(str) + final_df['Clase_XYZ'].astype(str)\n",
        "\n",
        "# 5. Exportar resultado final (solo clasificaciones)\n",
        "final_df.to_excel(\"Clasificacion_ABC_XYZ.xlsx\", index=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DataFrame final exportado con las columnas:\")\n",
        "print(final_df.columns.tolist())\n",
        "print(f\"\\nTotal de ítems clasificados: {len(final_df)}\")\n",
        "print(\"\\nEjemplo de clasificaciones:\")\n",
        "print(final_df.sample(min(5, len(final_df)), random_state=1))\n",
        "print(\"\\nDistribución de clasificaciones ABC-XYZ:\")\n",
        "print(final_df['Clasificacion_ABC_XYZ'].value_counts().sort_index())\n",
        "print(\"\\nResultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Z2pKld8aUC",
        "outputId": "f67e4872-e5dd-43d0-f930-30a9d3dc17fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DataFrame final exportado con las columnas:\n",
            "['ITEM', 'Clase_ABC', 'Clase_XYZ', 'Clasificacion_ABC_XYZ']\n",
            "\n",
            "Total de ítems clasificados: 660\n",
            "\n",
            "Ejemplo de clasificaciones:\n",
            "         ITEM Clase_ABC Clase_XYZ Clasificacion_ABC_XYZ\n",
            "547  ITEM 114         C         Z                    CZ\n",
            "353  ITEM 244         B         Y                    BY\n",
            "499  ITEM 570         C         Y                    CY\n",
            "173  ITEM 341         A         Y                    AY\n",
            "241  ITEM 427         A         Y                    AY\n",
            "\n",
            "Distribución de clasificaciones ABC-XYZ:\n",
            "Clasificacion_ABC_XYZ\n",
            "AX     77\n",
            "AY    116\n",
            "AZ    106\n",
            "BX     54\n",
            "BY     40\n",
            "BZ     53\n",
            "CX     87\n",
            "CY     68\n",
            "CZ     59\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Resultados exportados a 'Clasificacion_ABC_XYZ.xlsx'\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy.stats.mstats import winsorize\n",
        "from scipy.stats import norm\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/OPTIMIZACI-N-DE-INVENTARIOS-CON-POWER-BI/raw/refs/heads/main/Clases-PowerBi-Inventarios-Datos.xlsx\"\n",
        "\n",
        "# 1. Descargar y cargar datos\n",
        "response = requests.get(url)\n",
        "excel_data = BytesIO(response.content)\n",
        "\n",
        "# Leer todas las hojas necesarias\n",
        "historico_df = pd.read_excel(excel_data, sheet_name='Historico')\n",
        "forecast_df = pd.read_excel(excel_data, sheet_name='Forecast')\n",
        "precios_df = pd.read_excel(excel_data, sheet_name='Precios-Costos')\n",
        "lead_time_df = pd.read_excel(excel_data, sheet_name='LeadTime-Dias')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🚀 INICIANDO ANÁLISIS DE INVENTARIOS - ABC-XYZ + STOCK DE SEGURIDAD\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 1: CLASIFICACIÓN ABC\n",
        "# ============================================================================\n",
        "print(\"\\n📊 Calculando Clasificación ABC...\")\n",
        "\n",
        "# Limpiar y preparar datos para ABC\n",
        "forecast_df['ITEM'] = forecast_df['ITEM'].astype(str).str.strip()\n",
        "precios_df['ITEM'] = precios_df['ITEM'].astype(str).str.strip()\n",
        "forecast_df.columns = forecast_df.columns.str.strip()\n",
        "\n",
        "# Calcular ventas anuales\n",
        "monthly_cols = [col for col in forecast_df.columns if col != 'ITEM']\n",
        "forecast_df['Total_Ventas_Anual'] = forecast_df[monthly_cols].sum(axis=1)\n",
        "\n",
        "# Limpiar y convertir precios\n",
        "precios_df['Precio'] = precios_df['Precio'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "precios_df['Costo'] = precios_df['Costo'].astype(str).str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Unir datos y calcular valor total\n",
        "abc_df = forecast_df[['ITEM', 'Total_Ventas_Anual']].merge(\n",
        "    precios_df[['ITEM', 'Precio']], on='ITEM', how='inner')\n",
        "abc_df['Valor_Total_Dolares'] = abc_df['Total_Ventas_Anual'] * abc_df['Precio']\n",
        "\n",
        "# Ordenar y calcular acumulado\n",
        "abc_df = abc_df.sort_values('Valor_Total_Dolares', ascending=False)\n",
        "abc_df['Porcentaje_Acumulado'] = abc_df['Valor_Total_Dolares'].cumsum() / abc_df['Valor_Total_Dolares'].sum() * 100\n",
        "\n",
        "# Clasificar ABC\n",
        "def clasificar_abc(porcentaje):\n",
        "    if porcentaje <= 60: return 'A'\n",
        "    elif porcentaje <= 80: return 'B'\n",
        "    else: return 'C'\n",
        "\n",
        "abc_df['Clase_ABC'] = abc_df['Porcentaje_Acumulado'].apply(clasificar_abc)\n",
        "print(f\"   ✅ Items clasificados ABC: {len(abc_df)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 2: CLASIFICACIÓN XYZ\n",
        "# ============================================================================\n",
        "print(\"\\n📈 Calculando Clasificación XYZ...\")\n",
        "\n",
        "# Seleccionar últimos 18 meses de datos históricos para XYZ\n",
        "xyz_data = historico_df.set_index('ITEM').iloc[:, -18:].copy()\n",
        "\n",
        "# Función para limpiar datos XYZ\n",
        "def clean_row_xyz(row):\n",
        "    clean = row.copy().astype(float)\n",
        "    positive_vals = clean[clean > 0]\n",
        "    median_val = positive_vals.median() if not positive_vals.empty else 0\n",
        "    clean[clean <= 0] = median_val\n",
        "\n",
        "    if clean.nunique() > 1:\n",
        "        try:\n",
        "            clean[:] = winsorize(clean, limits=[0.05, 0.05])\n",
        "        except:\n",
        "            pass\n",
        "    return clean\n",
        "\n",
        "# Aplicar limpieza\n",
        "xyz_clean = xyz_data.apply(clean_row_xyz, axis=1)\n",
        "\n",
        "# Calcular coeficiente de variación\n",
        "mean = xyz_clean.mean(axis=1)\n",
        "std = xyz_clean.std(axis=1)\n",
        "cv = std / mean\n",
        "cv = cv.replace([np.inf, -np.inf], 1000).fillna(1000)\n",
        "\n",
        "# Clasificar XYZ\n",
        "p33 = cv.quantile(0.33)\n",
        "p67 = cv.quantile(0.67)\n",
        "\n",
        "xyz_df = pd.DataFrame({\n",
        "    'ITEM': xyz_clean.index.tolist(),\n",
        "    'CV': cv.values\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "xyz_df['Clase_XYZ'] = pd.cut(cv.values, bins=[-1, p33, p67, np.inf], labels=['X', 'Y', 'Z'])\n",
        "xyz_df['ITEM'] = xyz_df['ITEM'].astype(str).str.strip()\n",
        "\n",
        "print(f\"   ✅ Items clasificados XYZ: {len(xyz_df)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 3: COMBINAR ABC Y XYZ\n",
        "# ============================================================================\n",
        "print(\"\\n🔄 Combinando clasificaciones ABC-XYZ...\")\n",
        "\n",
        "abc_minimal = abc_df[['ITEM', 'Clase_ABC']].copy()\n",
        "abc_minimal['ITEM'] = abc_minimal['ITEM'].astype(str).str.strip()\n",
        "\n",
        "clasificacion_df = abc_minimal.merge(xyz_df[['ITEM', 'Clase_XYZ']], on='ITEM', how='inner')\n",
        "clasificacion_df['Clasificacion_ABC_XYZ'] = clasificacion_df['Clase_ABC'].astype(str) + clasificacion_df['Clase_XYZ'].astype(str)\n",
        "\n",
        "print(f\"   ✅ Items con clasificación completa: {len(clasificacion_df)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 4: CONFIGURAR NIVELES DE SERVICIO POR CLASIFICACIÓN\n",
        "# ============================================================================\n",
        "print(\"\\n⚙️ Configurando niveles de servicio por clasificación...\")\n",
        "\n",
        "# Diccionario de niveles de servicio según clasificación ABC-XYZ\n",
        "niveles_servicio = {\n",
        "    'AX': 0.95, 'AY': 0.90, 'AZ': 0.85,\n",
        "    'BX': 0.85, 'BY': 0.80, 'BZ': 0.75,\n",
        "    'CX': 0.75, 'CY': 0.70, 'CZ': 0.65\n",
        "}\n",
        "\n",
        "# Agregar nivel de servicio y Z-score\n",
        "clasificacion_df['Nivel_Servicio'] = clasificacion_df['Clasificacion_ABC_XYZ'].map(niveles_servicio)\n",
        "clasificacion_df['Z_Score'] = clasificacion_df['Nivel_Servicio'].apply(lambda x: norm.ppf(x) if pd.notna(x) else 1.645)\n",
        "\n",
        "print(\"   📋 Niveles de servicio configurados:\")\n",
        "for clase, nivel in niveles_servicio.items():\n",
        "    count = len(clasificacion_df[clasificacion_df['Clasificacion_ABC_XYZ'] == clase])\n",
        "    print(f\"      {clase}: {nivel*100:.0f}% (Z={norm.ppf(nivel):.3f}) - {count} items\")\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 5: CALCULAR STOCK DE SEGURIDAD\n",
        "# ============================================================================\n",
        "print(\"\\n🛡️ Calculando Stock de Seguridad...\")\n",
        "\n",
        "# Limpiar datos para stock de seguridad\n",
        "historico_df['ITEM'] = historico_df['ITEM'].str.strip()\n",
        "lead_time_df['ITEM'] = lead_time_df['ITEM'].str.strip()\n",
        "\n",
        "# Parámetros\n",
        "R_dias = 0.5\n",
        "WINSOR_LOW = 0.05\n",
        "WINSOR_HIGH = 0.95\n",
        "MIN_MESES_PARA_CALCULO = 12\n",
        "\n",
        "# Lista para resultados de stock de seguridad\n",
        "stock_resultados = []\n",
        "\n",
        "print(f\"   🔄 Procesando {len(clasificacion_df)} items...\")\n",
        "\n",
        "for idx, class_row in clasificacion_df.iterrows():\n",
        "    item = class_row['ITEM']\n",
        "    Z = class_row['Z_Score']\n",
        "\n",
        "    # Buscar el item en datos históricos\n",
        "    item_data = historico_df[historico_df['ITEM'] == item]\n",
        "\n",
        "    if len(item_data) == 0:\n",
        "        print(f\"      ⚠️ Item {item} no encontrado en histórico\")\n",
        "        stock_resultados.append({\n",
        "            'ITEM': item,\n",
        "            'Stock_Seguridad_Dias': np.nan,\n",
        "            'Promedio_Ventas_Mensual': np.nan,\n",
        "            'Desviacion_Ventas': np.nan,\n",
        "            'Lead_Time_Dias': np.nan\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # Extraer y convertir ventas\n",
        "    ventas = pd.to_numeric(item_data.iloc[0, 1:], errors='coerce')\n",
        "\n",
        "    # --- Paso 1: Imputar valores negativos ---\n",
        "    ventas_imp = ventas.copy()\n",
        "\n",
        "    negativos = ventas_imp < 0\n",
        "    for i in negativos[negativos].index:\n",
        "        try:\n",
        "            pos = list(ventas.index).index(i)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        inicio_ventana = max(0, pos - 12)\n",
        "        ventana = ventas.iloc[inicio_ventana:pos]\n",
        "        validos = ventana[(ventana > 0) & (ventana.notna())]\n",
        "\n",
        "        if len(validos) >= 3:\n",
        "            estimado = validos.median()\n",
        "        elif len(validos) > 0:\n",
        "            estimado = validos.mean()\n",
        "        else:\n",
        "            todos_positivos = ventas[(ventas > 0) & (ventas.notna())]\n",
        "            estimado = todos_positivos.mean() if len(todos_positivos) > 0 else 0\n",
        "\n",
        "        ventas_imp[i] = max(0, estimado)\n",
        "\n",
        "    ventas_imp = ventas_imp.clip(lower=0)\n",
        "\n",
        "    # --- Paso 2: Tomar los últimos 30 meses ---\n",
        "    ultimos_30_meses = ventas_imp[-30:]\n",
        "\n",
        "    if len(ultimos_30_meses.dropna()) < MIN_MESES_PARA_CALCULO:\n",
        "        stock_resultados.append({\n",
        "            'ITEM': item,\n",
        "            'Stock_Seguridad_Dias': np.nan,\n",
        "            'Promedio_Ventas_Mensual': np.nan,\n",
        "            'Desviacion_Ventas': np.nan,\n",
        "            'Lead_Time_Dias': np.nan\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # --- Winsorización ---\n",
        "    low_val = ultimos_30_meses.quantile(WINSOR_LOW)\n",
        "    high_val = ultimos_30_meses.quantile(WINSOR_HIGH)\n",
        "    ultimos_30_winsor = ultimos_30_meses.clip(lower=low_val, upper=high_val)\n",
        "\n",
        "    # Calcular promedio y desviación estándar\n",
        "    promedio_ventas = ultimos_30_winsor.mean()\n",
        "    desviacion = ultimos_30_winsor.std()\n",
        "\n",
        "    if pd.isna(desviacion) or desviacion == 0:\n",
        "        desviacion = 0.1 * promedio_ventas if promedio_ventas > 0 else 0.1\n",
        "\n",
        "    # --- Lead Time ---\n",
        "    if item in lead_time_df['ITEM'].values:\n",
        "        lt_row = lead_time_df[lead_time_df['ITEM'] == item].iloc[0, 1:]\n",
        "        lt_row = pd.to_numeric(lt_row, errors='coerce').dropna()\n",
        "        if len(lt_row) > 0:\n",
        "            promedio_lead_time_dias = lt_row.mean()\n",
        "        else:\n",
        "            promedio_lead_time_dias = 5\n",
        "    else:\n",
        "        promedio_lead_time_dias = 5\n",
        "\n",
        "    # Convertir L y R a meses\n",
        "    L = promedio_lead_time_dias / 30\n",
        "    R = R_dias / 30\n",
        "\n",
        "    # --- Calcular Stock de Seguridad ---\n",
        "    try:\n",
        "        SS_unidades = Z * desviacion * np.sqrt(L + R)\n",
        "    except:\n",
        "        SS_unidades = 0.1\n",
        "\n",
        "    # Convertir a días\n",
        "    if promedio_ventas > 0:\n",
        "        stock_seguridad_dias = (SS_unidades / promedio_ventas) * 30\n",
        "        stock_seguridad_dias = round(stock_seguridad_dias, 2)\n",
        "    else:\n",
        "        stock_seguridad_dias = 0.0\n",
        "\n",
        "    stock_resultados.append({\n",
        "        'ITEM': item,\n",
        "        'Stock_Seguridad_Dias': stock_seguridad_dias,\n",
        "        'Promedio_Ventas_Mensual': round(promedio_ventas, 2),\n",
        "        'Desviacion_Ventas': round(desviacion, 2),\n",
        "        'Lead_Time_Dias': round(promedio_lead_time_dias, 1)\n",
        "    })\n",
        "\n",
        "print(f\"   ✅ Stock de seguridad calculado para {len(stock_resultados)} items\")\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 6: CONSOLIDAR RESULTADOS FINALES\n",
        "# ============================================================================\n",
        "print(\"\\n📋 Consolidando resultados finales...\")\n",
        "\n",
        "# Crear DataFrame de stock de seguridad\n",
        "stock_df = pd.DataFrame(stock_resultados)\n",
        "\n",
        "# Unir todos los resultados\n",
        "resultado_final = clasificacion_df.merge(stock_df, on='ITEM', how='left')\n",
        "\n",
        "# Agregar información adicional útil\n",
        "resultado_final = resultado_final.merge(\n",
        "    abc_df[['ITEM', 'Total_Ventas_Anual', 'Precio', 'Valor_Total_Dolares']],\n",
        "    on='ITEM', how='left'\n",
        ")\n",
        "\n",
        "# Reordenar columnas para mejor presentación\n",
        "columnas_ordenadas = [\n",
        "    'ITEM', 'Clasificacion_ABC_XYZ', 'Clase_ABC', 'Clase_XYZ',\n",
        "    'Nivel_Servicio', 'Stock_Seguridad_Dias',\n",
        "    'Total_Ventas_Anual', 'Precio', 'Valor_Total_Dolares',\n",
        "    'Promedio_Ventas_Mensual', 'Desviacion_Ventas', 'Lead_Time_Dias'\n",
        "]\n",
        "\n",
        "resultado_final = resultado_final[columnas_ordenadas]\n",
        "\n",
        "# ============================================================================\n",
        "# PARTE 7: EXPORTAR Y MOSTRAR RESULTADOS\n",
        "# ============================================================================\n",
        "print(\"\\n💾 Exportando resultados...\")\n",
        "\n",
        "# Exportar a Excel\n",
        "resultado_final.to_excel(\"Analisis_Completo_ABC_XYZ_Stock_Seguridad.xlsx\", index=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"📊 RESUMEN DE RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n🎯 Total de ítems analizados: {len(resultado_final)}\")\n",
        "print(f\"📈 Items con datos completos: {len(resultado_final.dropna())}\")\n",
        "\n",
        "print(\"\\n📊 Distribución por Clasificación ABC-XYZ:\")\n",
        "distribucion = resultado_final['Clasificacion_ABC_XYZ'].value_counts().sort_index()\n",
        "for clase, cantidad in distribucion.items():\n",
        "    nivel = niveles_servicio.get(clase, 0)\n",
        "    print(f\"   {clase}: {cantidad:3d} items (Nivel servicio: {nivel*100:.0f}%)\")\n",
        "\n",
        "print(f\"\\n💰 Stock de Seguridad Promedio por Clasificación (días):\")\n",
        "stock_promedio = resultado_final.groupby('Clasificacion_ABC_XYZ')['Stock_Seguridad_Dias'].agg(['mean', 'count']).round(1)\n",
        "for clase, stats in stock_promedio.iterrows():\n",
        "    if not pd.isna(stats['mean']):\n",
        "        print(f\"   {clase}: {stats['mean']:6.1f} días promedio ({int(stats['count'])} items)\")\n",
        "\n",
        "print(f\"\\n📋 Ejemplo de resultados:\")\n",
        "muestra = resultado_final[['ITEM', 'Clasificacion_ABC_XYZ', 'Nivel_Servicio', 'Stock_Seguridad_Dias', 'Valor_Total_Dolares']].head(10)\n",
        "print(muestra.to_string(index=False))\n",
        "\n",
        "print(f\"\\n✅ Resultados exportados a: 'Analisis_Completo_ABC_XYZ_Stock_Seguridad.xlsx'\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ2oPzxwFpNa",
        "outputId": "8d105c6c-79f3-477e-f0b6-9af97140c23f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🚀 INICIANDO ANÁLISIS DE INVENTARIOS - ABC-XYZ + STOCK DE SEGURIDAD\n",
            "================================================================================\n",
            "\n",
            "📊 Calculando Clasificación ABC...\n",
            "   ✅ Items clasificados ABC: 660\n",
            "\n",
            "📈 Calculando Clasificación XYZ...\n",
            "   ✅ Items clasificados XYZ: 660\n",
            "\n",
            "🔄 Combinando clasificaciones ABC-XYZ...\n",
            "   ✅ Items con clasificación completa: 660\n",
            "\n",
            "⚙️ Configurando niveles de servicio por clasificación...\n",
            "   📋 Niveles de servicio configurados:\n",
            "      AX: 95% (Z=1.645) - 77 items\n",
            "      AY: 90% (Z=1.282) - 116 items\n",
            "      AZ: 85% (Z=1.036) - 106 items\n",
            "      BX: 85% (Z=1.036) - 54 items\n",
            "      BY: 80% (Z=0.842) - 40 items\n",
            "      BZ: 75% (Z=0.674) - 53 items\n",
            "      CX: 75% (Z=0.674) - 87 items\n",
            "      CY: 70% (Z=0.524) - 68 items\n",
            "      CZ: 65% (Z=0.385) - 59 items\n",
            "\n",
            "🛡️ Calculando Stock de Seguridad...\n",
            "   🔄 Procesando 660 items...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-190412712.py:223: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  ultimos_30_winsor = ultimos_30_meses.clip(lower=low_val, upper=high_val)\n",
            "/tmp/ipython-input-190412712.py:223: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  ultimos_30_winsor = ultimos_30_meses.clip(lower=low_val, upper=high_val)\n",
            "/tmp/ipython-input-190412712.py:203: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24132.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  ventas_imp[i] = max(0, estimado)\n",
            "/tmp/ipython-input-190412712.py:223: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  ultimos_30_winsor = ultimos_30_meses.clip(lower=low_val, upper=high_val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Stock de seguridad calculado para 660 items\n",
            "\n",
            "📋 Consolidando resultados finales...\n",
            "\n",
            "💾 Exportando resultados...\n",
            "================================================================================\n",
            "📊 RESUMEN DE RESULTADOS\n",
            "================================================================================\n",
            "\n",
            "🎯 Total de ítems analizados: 660\n",
            "📈 Items con datos completos: 660\n",
            "\n",
            "📊 Distribución por Clasificación ABC-XYZ:\n",
            "   AX:  77 items (Nivel servicio: 95%)\n",
            "   AY: 116 items (Nivel servicio: 90%)\n",
            "   AZ: 106 items (Nivel servicio: 85%)\n",
            "   BX:  54 items (Nivel servicio: 85%)\n",
            "   BY:  40 items (Nivel servicio: 80%)\n",
            "   BZ:  53 items (Nivel servicio: 75%)\n",
            "   CX:  87 items (Nivel servicio: 75%)\n",
            "   CY:  68 items (Nivel servicio: 70%)\n",
            "   CZ:  59 items (Nivel servicio: 65%)\n",
            "\n",
            "💰 Stock de Seguridad Promedio por Clasificación (días):\n",
            "   AX:    3.3 días promedio (77 items)\n",
            "   AY:    2.8 días promedio (116 items)\n",
            "   AZ:    2.4 días promedio (106 items)\n",
            "   BX:    2.3 días promedio (54 items)\n",
            "   BY:    1.9 días promedio (40 items)\n",
            "   BZ:    1.7 días promedio (53 items)\n",
            "   CX:    1.4 días promedio (87 items)\n",
            "   CY:    1.2 días promedio (68 items)\n",
            "   CZ:    0.9 días promedio (59 items)\n",
            "\n",
            "📋 Ejemplo de resultados:\n",
            "    ITEM Clasificacion_ABC_XYZ  Nivel_Servicio  Stock_Seguridad_Dias  Valor_Total_Dolares\n",
            " ITEM 12                    AY            0.90                  2.87          38281089.60\n",
            "  ITEM 2                    AY            0.90                  3.35          34579341.36\n",
            "  ITEM 1                    AX            0.95                  2.47          33017418.72\n",
            "  ITEM 7                    AZ            0.85                  1.87          31979129.40\n",
            "ITEM 311                    AZ            0.85                  3.09          29629964.16\n",
            " ITEM 45                    AZ            0.85                  3.42          29465411.76\n",
            "ITEM 121                    AY            0.90                  2.87          28942273.92\n",
            "ITEM 421                    AY            0.90                  2.81          28059164.28\n",
            " ITEM 63                    AY            0.90                  2.84          27314733.60\n",
            "ITEM 362                    AY            0.90                  2.48          27215445.60\n",
            "\n",
            "✅ Resultados exportados a: 'Analisis_Completo_ABC_XYZ_Stock_Seguridad.xlsx'\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}